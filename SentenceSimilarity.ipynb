{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd088dbe2f50565cb9d6bb287b421ac62e2261ef7a3703ea742e9e1e752c4226eb4",
   "display_name": "Python 3.8.8 64-bit ('Research': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "88dbe2f50565cb9d6bb287b421ac62e2261ef7a3703ea742e9e1e752c4226eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-nli-mean-tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\nidbh/.cache\\torch\\sentence_transformers\\sbert.net_models_bert-base-nli-mean-tokens\\0_BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "array = cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")\n",
    "np.argmax(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context = \"Obama addressed the press at white house conference\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "References = [\n",
    "    \"the press are eager to listen obama's say at the meeting\",\n",
    "    \"Obama talked with the press at the presidential white house meet\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context_Embedding = model.encode(Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "References_Embedding = model.encode(References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = cosine_similarity(Context_Embedding, References_Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Obama talked with the press at the presidential white house meet'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "References[np.argmax(array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.6746562 0.962698 ] 0\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(array):\n",
    "    print(i, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in array:\n",
    "    x = i.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.762697982788086\n0.762697982788086\n"
     ]
    }
   ],
   "source": [
    "for i in x :\n",
    "    if i < np.max(array) and i > np.max(array) - 0.2:\n",
    "        print(i)\n",
    "    print(np.max(array) - 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6746562123298645\n0.9626979827880859\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "# Hugging Face Transformers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (1.20.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\nidbh\\anaconda3\\envs\\research\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nidbh\\appdata\\roaming\\python\\python38\\site-packages (from click->sacremoses->transformers) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1.65k/1.65k [00:00<00:00, 419kB/s]\n",
      "Downloading: 100%|██████████| 1.22G/1.22G [05:24<00:00, 3.77MB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:23<00:00, 38.8kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:14<00:00, 32.4kB/s]\n",
      "Downloading: 100%|██████████| 26.0/26.0 [00:00<00:00, 4.02kB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')"
   ]
  }
 ]
}